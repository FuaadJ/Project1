{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\F\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\stable_baselines\\__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "# Download packages\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from yahoofinancials import YahooFinancials\n",
    "from pandas_datareader import data\n",
    "import numpy as np\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import datetime as dt\n",
    "import random\n",
    "\n",
    "\n",
    "import gym\n",
    "#import json\n",
    "import datetime as dt\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines import A2C\n",
    "#from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "import gym\n",
    "from gym import spaces\n",
    "\t\n",
    "from yahoo_fin.stock_info import get_analysts_info\n",
    "import yahoo_fin.stock_info as si\n",
    "#import optuna\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  26 of 26 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SWMA.ST: No data found, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download stock data\n",
    "\n",
    "\n",
    "\n",
    "stocks = ['KINV-B.ST','TELIA.ST','NDA-SE.ST','SWMA.ST','TEL2-B.ST','ASSA-B.ST'\n",
    ",'ERIC-B.ST','VOLV-B.ST','ELUX-B.ST','ABB.ST','ALIV-SDB.ST'\n",
    ",'AZN.ST','SEB-A.ST','SKF-B.ST','SHB-A.ST'\n",
    ",'ALFA.ST','INVE-B.ST','GETI-B.ST','HM-B.ST','SWED-A.ST'\n",
    ",'HEXA-B.ST','ATCO-B.ST','SCA-B.ST','ATCO-A.ST','BOL.ST','SAND.ST']\n",
    "\n",
    "\n",
    "# EVO.ST','ESSITY-B.ST',,'SINCH.ST','SBB-B.ST'\n",
    "start='2010-01-01'\n",
    "end='2015-01-01'\n",
    "df = yf.download(stocks, \n",
    "                      start, \n",
    "                      end, \n",
    "                      progress=True)\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "omx = yf.download('^OMX', \n",
    "                      start, \n",
    "                      end, \n",
    "                      progress=True)\n",
    "omx.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "omx = yf.download('^OMX', \n",
    "                      start, \n",
    "                      end, \n",
    "                      progress=True)\n",
    "omx.reset_index(inplace=True)\n",
    "\n",
    "omx = omx.loc[:,'Open']\n",
    "\n",
    "Open=df.loc[:,'Open'].values\n",
    "Close=df.loc[:,'Adj Close'].values\n",
    "High=df.loc[:,'High'].values\n",
    "Low=df.loc[:,'Low'].values\n",
    "# Fix splits\n",
    "#Open[630:,2] +=400\n",
    "\n",
    "LOW=Low[1:,:]/Low[:-1,:]\n",
    "\n",
    "HIGH=High[1:,:]/High[:-1,:]\n",
    "\n",
    "OPEN = Open[1:,:]/Open[:-1,:]\n",
    "\n",
    "\n",
    "#LOW=Low.iloc[1:,:].values\n",
    "LOW= np.divide(LOW-np.min(LOW,axis=0),np.max(LOW,axis=0)-np.min(LOW,axis=0))\n",
    "\n",
    "#HIGH=High.iloc[1:,:].values\n",
    "HIGH= np.divide(HIGH-np.min(HIGH,axis=0),np.max(HIGH,axis=0)-np.min(HIGH,axis=0))\n",
    "\n",
    "#OPEN = Open.iloc[1:,:].values\n",
    "\n",
    "OPEN= np.divide(OPEN-np.min(OPEN,axis=0),np.max(OPEN,axis=0)-np.min(OPEN,axis=0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = pd.date_range(start, end,freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "\n",
    "\n",
    "#Dimensions for data\n",
    "frame_end = 15\n",
    "Dim =10\n",
    "\n",
    "Stocks = 26\n",
    "\n",
    "class Test7():\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self,LOW,HIGH,OPEN,Open,portfolio_start,frame_end,Stocks,Reward_function):\n",
    "\n",
    "\n",
    "        self.open = OPEN\n",
    "        self.low = LOW\n",
    "        self.high = HIGH\n",
    "        self.data = Open\n",
    "\n",
    "        self.portfolio_start = portfolio_start\n",
    "        self.Portfolio_balance = portfolio_start\n",
    "\n",
    "        self.done = False\n",
    "\n",
    "        self.shares_hold = 0\n",
    "        self.fees = 0.001 # cost of buying stock\n",
    "\n",
    "        self.total_sale = 0\n",
    "        self.total_buy = 0\n",
    "        self.total_fees = 0\n",
    "        self.share_hold = 0\n",
    "        self.share_hold_time = np.zeros((len(self.data),Stocks))\n",
    "\n",
    "        self.buy_position = [0]*Stocks\n",
    "        self.sell_position = [0]*Stocks\n",
    "        self.reward_history = [0]*len(self.data)\n",
    "        self.cash = self.portfolio_start\n",
    "        self.stock_value = 0\n",
    "        self.cash2stock_ratio = [0]*len(self.data)\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        #self.frame_start = frame_start\n",
    "        self.frame_end = frame_end\n",
    "\n",
    "\n",
    "\n",
    "        # start data at 1 due to scaling\n",
    "        self.tic = self.frame_end+1\n",
    "        self.end = len(self.data)-self.frame_end-1\n",
    "\n",
    "        self.net =[0]*len(self.data)\n",
    "        self.sig_p =[0]*len(self.data)\n",
    "        self.net.insert(self.tic,self.Portfolio_balance)\n",
    "        \n",
    "        self.Value_at_risk =[1]*len(self.data)\n",
    "\n",
    "        self.plot_balance =[0]*len(self.data)\n",
    "        self.plot_balance.insert(self.tic,self.Portfolio_balance)\n",
    "        \n",
    "\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(3,frame_end,Stocks), dtype=np.float32)                            \n",
    "        self.action_space = spaces.Box(low = -1, high = 1,shape = (Stocks,)) \n",
    "\n",
    "\n",
    "    def Look_space(self):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Look_1 = np.array([self.open[self.tic-self.frame_end: self.tic, :],\n",
    "            self.low[self.tic-self.frame_end: self.tic,:],\n",
    "             self.high[self.tic-self.frame_end: self.tic,:]])\n",
    "    \n",
    "            \n",
    "\n",
    "       \n",
    "            \n",
    "\n",
    "        return Look_1\n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        self.done = False\n",
    "\n",
    "        self.tic =self.frame_end+1\n",
    "\n",
    "        self.reward = 0\n",
    "        self.shares = 0\n",
    "        self.share_hold_time = np.zeros((len(self.data),Stocks))\n",
    "\n",
    "        self.Portfolio_balance = self.portfolio_start\n",
    "\n",
    "        \n",
    "\n",
    "        self.end = len(self.data)-self.frame_end-1\n",
    "\n",
    "\n",
    "        self.total_sale = 0\n",
    "        self.total_buy = 0\n",
    "        self.total_fees = 0\n",
    "        self.share_hold = [0]*Stocks\n",
    "        \n",
    "        self.cash = self.portfolio_start\n",
    "        self.stock_value = 0\n",
    "        self.cash2stock_ratio = [0]*len(self.data)\n",
    "\n",
    "\n",
    "     \n",
    "        self.buy_position = [0]*Stocks\n",
    "        self.sell_position = [0]*Stocks\n",
    "        self.reward_history = [0]*len(self.data)\n",
    "\n",
    "        self.net =[0]*len(self.data)\n",
    "        self.net.insert(self.tic,self.Portfolio_balance)\n",
    "\n",
    "        self.Value_at_risk =[1]*len(self.data)\n",
    "\n",
    "        self.plot_balance =[0]*len(self.data)\n",
    "        self.sig_p =[0]*len(self.data)\n",
    "        self.plot_balance.insert(self.tic,self.Portfolio_balance)\n",
    "\n",
    "        self.frame_end = frame_end\n",
    "        self.frame_start= frame_end\n",
    "\n",
    "        state = self.Look_space()\n",
    "\n",
    "        \n",
    "\n",
    "        return state\n",
    "    \n",
    "\n",
    "    def buy_sell(self,action,index):\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        # when does the stock buy? randomly?\n",
    "        share_price =  self.data[self.tic, :]\n",
    "        share_price1 = share_price[index]\n",
    "        \n",
    "        \n",
    "\n",
    "        action_space = action\n",
    "        amount =action*Dim\n",
    " \n",
    "    \n",
    "\n",
    "\n",
    "        if  action_space>0 and self.Portfolio_balance>0 :\n",
    "\n",
    "            # Buy stocks\n",
    "            P_buy =self.Portfolio_balance/(share_price1)\n",
    "            amount_buy = min(amount,P_buy)\n",
    "            buy = share_price1*amount_buy\n",
    "            cost_penalty = buy*self.fees\n",
    "            #self.buy_position.append(self.tic)\n",
    "\n",
    "\n",
    "\n",
    "            self.Portfolio_balance -=cost_penalty+buy\n",
    "            self.share_hold[index]+= amount_buy\n",
    "            \n",
    "           \n",
    "            \n",
    "\n",
    "\n",
    "        if action_space<0 and self.share_hold[index]>0:\n",
    "            #Sell\n",
    "            amount_sell = min(self.share_hold[index],abs(amount))\n",
    "            #self.sell_position.append(self.tic)\n",
    "\n",
    "            sold_amount = share_price1*amount_sell\n",
    "            cost_penalty = sold_amount*self.fees\n",
    "\n",
    "            self.Portfolio_balance +=sold_amount-cost_penalty\n",
    "\n",
    "            self.share_hold[index] -= amount_sell\n",
    "\n",
    "    def step(self,action):\n",
    "        self.tic += 1\n",
    "        a = np.array(action)\n",
    "\n",
    "\n",
    "        index = 0\n",
    "        for action in a:\n",
    "            self.buy_sell(action,index)\n",
    "            index +=1\n",
    "\n",
    "\n",
    "        self.share_hold_time[self.tic,:] = self.share_hold\n",
    "\n",
    "        self.stock_value = np.dot(self.share_hold,self.data[self.tic, :])\n",
    "        self.cash = self.Portfolio_balance\n",
    "        self.cash2stock_ratio.insert(self.tic,self.stock_value/self.cash)\n",
    "\n",
    "        self.plot_balance.insert(self.tic,self.Portfolio_balance+np.dot(self.share_hold,self.data[self.tic, :]))\n",
    "        R1 = np.divide(self.plot_balance[self.tic],self.plot_balance[self.tic-1])\n",
    "        self.net.insert(self.tic,R1-1)\n",
    "        matrix = np.corrcoef(self.data[self.tic-self.frame_end: self.tic, :],rowvar=False)\n",
    "        weights =np.divide(np.multiply(self.data[self.tic, :],self.share_hold),self.plot_balance[self.tic])\n",
    "        portfolio_vol = np.sqrt(np.dot(np.transpose(weights),np.dot(matrix,weights)))\n",
    "\n",
    "        self.sig_p.insert(self.tic,portfolio_vol)\n",
    "\n",
    "\n",
    "        if Reward_function==1:\n",
    " \n",
    "            \n",
    "            # Reward function Sharpe ratio\n",
    "            R =np.divide(self.plot_balance[self.tic],self.plot_balance[self.tic-1])\n",
    "            self.reward = np.divide(R,portfolio_vol)\n",
    "            reward = np.divide(R-1,portfolio_vol)\n",
    "        elif Reward_function==2:\n",
    "            #Standard\n",
    "            self.reward = (self.plot_balance[self.tic]-self.plot_balance[self.tic-1])\n",
    "            reward = (self.reward /self.plot_balance[self.tic])\n",
    "        elif Reward_function==3:\n",
    "            R = (self.plot_balance[self.tic]/self.plot_balance[self.tic-1])\n",
    "            self.Value_at_risk.insert(self.tic,R)\n",
    "            K = np.sort(resample(self.Value_at_risk[self.tic-self.frame_end: self.tic],n_samples=20,replace=True))\n",
    "            reward = R-0.5*K[2]\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        self.reward_history.insert(self.tic,reward)\n",
    "\n",
    "        obs = self.Look_space() \n",
    "\n",
    "\n",
    "\n",
    "        if self.tic >self.end :\n",
    "            self.done = True\n",
    "            self.Portfolio_balance += np.dot(self.share_hold,self.data[self.tic, :])*(1-self.fees)\n",
    "            #self.render()\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return obs, reward, self.done, {}\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reset() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11888\\2919961234.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTest7\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: reset() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model and saving it.\n",
    "# Use tensorboard to evaluat the best model\n",
    "\n",
    "\n",
    "log_path =\"logs_netarch_0.001\"\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "\n",
    "for i in range(1,4):\n",
    "    \n",
    "\n",
    "    if i==1:\n",
    "\n",
    "        Reward_function = 1\n",
    "        Test = DummyVecEnv([lambda: Test7(LOW,HIGH,OPEN,Open,100000,frame_end,Stocks,Reward_function)])\n",
    "        policy_kwargs = dict(act_fun=tf.nn.tanh, net_arch=[64, 64])\n",
    "        model = PPO2(MlpPolicy, Test, verbose=1,policy_kwargs=policy_kwargs,tensorboard_log=log_path)\n",
    "        models_dir =\"models/Test_3_Sharp_64_64\"\n",
    "        if not os.path.exists( models_dir):\n",
    "             os.makedirs( models_dir)\n",
    "        Timestep = 10000\n",
    "        for i in range(1,100):\n",
    "            model.learn(total_timesteps=Timestep,reset_num_timesteps=False,tb_log_name=\"Test_3_Sharp_64_64\")\n",
    "            model.save(f\"{models_dir}/{Timestep*i}\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    if i==2:\n",
    "        Reward_function = 1\n",
    "        Test = DummyVecEnv([lambda: Test7(LOW,HIGH,OPEN,Open,100000,frame_end,Stocks,Reward_function)])\n",
    "        policy_kwargs = dict(act_fun=tf.nn.tanh, net_arch=[256, 256])\n",
    "        model = PPO2(MlpPolicy, Test, verbose=1,policy_kwargs=policy_kwargs,tensorboard_log=log_path)\n",
    "        models_dir =\"models/Test_3_Sharp_256_256\"\n",
    "        if not os.path.exists(models_dir):\n",
    "             os.makedirs(models_dir)\n",
    "        Timestep = 10000\n",
    "        for i in range(1,100):\n",
    "            model.learn(total_timesteps=Timestep,reset_num_timesteps=False,tb_log_name=\"Test_3_Sharp_256_256\")\n",
    "            model.save(f\"{models_dir}/{Timestep*i}\")\n",
    "        \n",
    "    if i==3:\n",
    "        Reward_function = 1\n",
    "        Test = DummyVecEnv([lambda: Test7(LOW,HIGH,OPEN,Open,100000,frame_end,Stocks,Reward_function)])\n",
    "        policy_kwargs = dict(act_fun=tf.nn.tanh, net_arch=[512, 512])\n",
    "        model = PPO2(MlpPolicy, Test, verbose=1,policy_kwargs=policy_kwargs,tensorboard_log=log_path)\n",
    "        models_dir =\"models/Test_3_Sharp_512_512\"\n",
    "        if not os.path.exists(models_dir):\n",
    "             os.makedirs(models_dir)\n",
    "        Timestep = 10000\n",
    "        for i in range(1,100):\n",
    "            model.learn(total_timesteps=Timestep,reset_num_timesteps=False,tb_log_name=\"Test_3_Sharp_512_512\")\n",
    "            model.save(f\"{models_dir}/{Timestep*i}\")\n",
    "      \n",
    "\n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cf032336d61a4c6e6c317cf196f0215645f2ac2677e1706b497455622df23ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
